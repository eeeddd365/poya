import os
import time
from playwright.sync_api import sync_playwright
from supabase import create_client

# ç’°å¢ƒè®Šæ•¸
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# å¯¶é›…æ­£ç¢ºçš„åˆ†é¡ ID
CATEGORIES = {
    "ç´™æ£‰ç”¨å“": "260",
    "å±…å®¶æ¸…æ½”": "261",
    "ç”Ÿæ´»é›œè²¨": "262",
    "ç”Ÿæ´»ç”¨å“": "263"
}

def scrape_poya():
    with sync_playwright() as p:
        # ä½¿ç”¨ chromium ä¸¦å½è£ User-Agent
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
            viewport={'width': 1280, 'height': 800}
        )
        page = context.new_page()

        for cat_name, cat_id in CATEGORIES.items():
            url = f"https://www.poyabuy.com.tw/v2/official/SalePageCategory/{cat_id}"
            print(f"ğŸš€ é–‹å§‹æŠ“å–åˆ†é¡: {cat_name} (ID: {cat_id})")
            
            try:
                # å»¶é•·ç­‰å¾…æ™‚é–“ä¸¦ç¢ºä¿ç¶²é å®Œå…¨è®€å–
                page.goto(url, wait_until="networkidle", timeout=60000)
                page.wait_for_timeout(5000)

                # æ¨¡æ“¬çœŸå¯¦äººé¡æ»¾å‹•
                for i in range(3):
                    page.mouse.wheel(0, 1500)
                    time.sleep(2)

                # æŠ“å–æ‰€æœ‰å¯èƒ½æ˜¯å•†å“å¡ç‰‡çš„å…ƒç´  (æ”¹ç”¨æ›´é€šç”¨çš„é¸æ“‡å™¨)
                # å¯¶é›…ç›®å‰å¯èƒ½ä½¿ç”¨ .sc-... æˆ–æ˜¯ .product-card é¡çš„åç¨±
                products = page.locator("[class*='ProductCard'], .product-card-m").all()
                print(f"æ‰¾åˆ° {len(products)} å€‹æ½›åœ¨å•†å“å…ƒç´ ")

                data_list = []
                for item in products:
                    try:
                        # æŠ“å–æ¨™é¡Œå’Œåœ–ç‰‡
                        title = item.locator("[class*='title'], [class*='Name']").first.inner_text()
                        img_element = item.locator("img").first
                        img_url = img_element.get_attribute("src") or img_element.get_attribute("data-src")
                        
                        if title and img_url:
                            # ç¢ºä¿åœ–ç‰‡ç¶²å€å®Œæ•´
                            if img_url.startswith("//"):
                                img_url = "https:" + img_url
                                
                            data_list.append({
                                "title": title.strip(),
                                "image_url": img_url,
                                "category": cat_name
                            })
                    except:
                        continue
                
                # å¯«å…¥ Supabase
                if data_list:
                    print(f"ğŸ’¾ æ­£åœ¨å­˜å…¥ {len(data_list)} ç­†è³‡æ–™åˆ° Supabase...")
                    supabase.table("poya_items").upsert(data_list, on_conflict="title").execute()
                else:
                    print(f"âš ï¸ åˆ†é¡ {cat_name} æ²’æŠ“åˆ°ä»»ä½•å•†å“ï¼Œå¯èƒ½ç¶²ç«™çµæ§‹è®Šæ›´äº†ã€‚")

            except Exception as e:
                print(f"âŒ æŠ“å– {cat_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        browser.close()

if __name__ == "__main__":
    scrape_poya()
