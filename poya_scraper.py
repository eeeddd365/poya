import os
import time
from playwright.sync_api import sync_playwright
from supabase import create_client

# 1. åˆå§‹åŒ– Supabase
# è«‹ç¢ºä¿ GitHub Secrets å·²è¨­å®š SUPABASE_URL èˆ‡ SUPABASE_KEY
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# 2. å®šç¾©æ­£ç¢ºçš„åˆ†é¡ ID (æ ¹æ“šå¯¶é›…æœ€æ–°ç¶²å€çµæ§‹)
CATEGORIES = {
    "ç´™æ£‰ç”¨å“": "374016",
    "å±…å®¶æ¸…æ½”": "374018",
    "ç”Ÿæ´»é›œè²¨": "381590",
    "ç”Ÿæ´»ç”¨å“": "374020"
}

def scrape_poya():
    with sync_playwright() as p:
        # å•Ÿå‹• Chrome ç€è¦½å™¨
        browser = p.chromium.launch(headless=True)
        # æ¨¡æ“¬çœŸå¯¦ä½¿ç”¨è€…ç’°å¢ƒï¼Œé¿å…è¢«åµæ¸¬ç‚ºæ©Ÿå™¨äºº
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
            viewport={'width': 1280, 'height': 800}
        )
        page = context.new_page()

        for cat_name, cat_id in CATEGORIES.items():
            # ä½¿ç”¨æ­£ç¢ºçš„ç¶²å€æ ¼å¼ä¸¦åŠ ä¸ŠéŠ·é‡æ’åºï¼Œå¢åŠ æ¸²æŸ“æˆåŠŸç‡
            target_url = f"https://www.poyabuy.com.tw/v2/official/SalePageCategory/{cat_id}?sortMode=Sales"
            print(f"ğŸš€ æ­£åœ¨çˆ¬å–åˆ†é¡: {cat_name} (ID: {cat_id})")
            
            try:
                # è¨ªå•ç¶²å€ï¼Œç­‰å¾…ç¶²çµ¡é–’ç½®
                page.goto(target_url, wait_until="networkidle", timeout=60000)
                
                # çµ¦äºˆé¡å¤–æ™‚é–“è®“å‹•æ…‹å…ƒä»¶ï¼ˆå•†å“åˆ—è¡¨ï¼‰ç”Ÿæˆ
                page.wait_for_timeout(8000)

                # æ¨¡æ“¬æ»¾å‹•ï¼Œè§¸ç™¼ Lazy Load è¼‰å…¥æ›´å¤šå•†å“åœ–
                page.mouse.wheel(0, 2000)
                page.wait_for_timeout(3000)

                # æŠ“å–æ‰€æœ‰åŒ…å«å•†å“é€£çµçš„ A æ¨™ç±¤ (91APP æ ¸å¿ƒç‰¹å¾µç‚º SalePage)
                product_nodes = page.locator("a[href*='SalePage']").all()
                print(f"ğŸ” åµæ¸¬åˆ° {len(product_nodes)} å€‹å•†å“ç¯€é»...")

                data_list = []
                for node in product_nodes:
                    try:
                        # æŠ“å–æ¨™é¡Œ (é€šå¸¸åœ¨ A æ¨™ç±¤å…§éƒ¨çš„æ–‡å­—)
                        # æˆ‘å€‘å–ç¬¬ä¸€è¡Œéç©ºçš„æ–‡å­—
                        full_text = node.inner_text().strip()
                        if not full_text: continue
                        title = full_text.split('\n')[0]

                        # æŠ“å–åœ–ç‰‡ï¼šå…ˆæ‰¾ srcï¼Œè‹¥ç„¡å‰‡æ‰¾ data-src
                        img_el = node.locator("img").first
                        img_url = img_el.get_attribute("src") or img_el.get_attribute("data-src")

                        # ç¯©é¸æ¢ä»¶ï¼šæ¨™é¡Œé•·åº¦åˆç†ã€åœ–ç‰‡ç¶²å€å­˜åœ¨ã€ä¸”éè£é£¾ç”¨çš„å°åœ–
                        if title and img_url and len(title) > 4:
                            # è£œå…¨ç¶²å€å”è­°
                            if img_url.startswith("//"):
                                img_url = "https:" + img_url
                            
                            # æ’é™¤éå•†å“çš„éœæ…‹ icon æˆ–å»£å‘Š
                            if "static" not in img_url and "Banner" not in img_url:
                                data_list.append({
                                    "title": title,
                                    "image_url": img_url,
                                    "category": cat_name,
                                    "updated_at": "now()"
                                })
                    except:
                        continue

                # å°‡çµæœå¯«å…¥ Supabase
                if data_list:
                    # ä½¿ç”¨å­—å…¸é€²è¡Œæ¨™é¡Œå»é‡ï¼Œé¿å…é‡è¤‡å¯«å…¥
                    unique_data = {v['title']: v for v in data_list}.values()
                    print(f"ğŸ’¾ æ­£åœ¨å°‡ {len(unique_data)} ç­†è³‡æ–™å­˜å…¥ Supabase...")
                    
                    # ä½¿ç”¨ upsert æ ¹æ“š title (Primary Key) æ›´æ–°æˆ–æ’å…¥
                    supabase.table("poya_items").upsert(list(unique_data), on_conflict="title").execute()
                    print(f"âœ… {cat_name} æŠ“å–ä¸¦æ›´æ–°å®Œæˆã€‚")
                else:
                    print(f"âš ï¸ {cat_name} æœªæŠ“åˆ°æœ‰æ•ˆæ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²é æ˜¯å¦è¢«æ“‹ã€‚")

            except Exception as e:
                print(f"âŒ åŸ·è¡Œ {cat_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        browser.close()

if __name__ == "__main__":
    scrape_poya()
