import os
import json
from playwright.sync_api import sync_playwright
from supabase import create_client

# ç’°å¢ƒè®Šæ•¸
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# åˆ†é¡å°æ‡‰åç¨±
CATEGORIES = {
    "260": "ç´™æ£‰ç”¨å“",
    "261": "å±…å®¶æ¸…æ½”",
    "262": "ç”Ÿæ´»é›œè²¨",
    "263": "ç”Ÿæ´»ç”¨å“"
}

def scrape_poya():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        # æ¨¡æ“¬å®Œå…¨çœŸå¯¦çš„æ‰‹æ©Ÿç€è¦½å™¨
        context = browser.new_context(
            user_agent="Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1"
        )
        page = context.new_page()

        all_products = []

        # ç›£è½å¾Œç«¯ API éŸ¿æ‡‰
        def handle_response(response):
            # å°‹æ‰¾åŒ…å«å•†å“æ¸…å–®çš„ API ç¶²å€ (91APP å¸¸ç”¨é—œéµå­—: SearchList)
            if "SearchList" in response.url and response.status == 200:
                try:
                    data = response.json()
                    # 91APP çš„ JSON çµæ§‹é€šå¸¸åœ¨ Data.Entries è£¡
                    items = data.get("Data", {}).get("Entries", [])
                    print(f"ğŸ“¡ æ””æˆªåˆ° API æ•¸æ“šï¼Œå–å¾— {len(items)} å€‹å“é …")
                    
                    for item in items:
                        title = item.get("Title")
                        # å–å¾—é«˜æ¸…åŸåœ–
                        img = item.get("CoverImageUrl")
                        if title and img:
                            all_products.append({
                                "title": title,
                                "image_url": "https:" + img if img.startswith("//") else img,
                                # æ ¹æ“š URL åˆ¤æ–·åˆ†é¡ï¼Œé€™è£¡ç¨å¾Œè™•ç†
                                "category": "æœªåˆ†é¡" 
                            })
                except Exception as e:
                    print(f"è§£æ API éŒ¯èª¤: {e}")

        page.on("response", handle_response)

        for cat_id, cat_name in CATEGORIES.items():
            target_url = f"https://www.poyabuy.com.tw/v2/official/SalePageCategory/{cat_id}"
            print(f"ğŸš€ æ­£åœ¨é–‹å•Ÿåˆ†é¡ç¶²å€: {cat_name}...")
            
            # è¨ªå•ç¶²å€æœƒè§¸ç™¼èƒŒæ™¯ API èª¿ç”¨
            page.goto(target_url, wait_until="networkidle", timeout=60000)
            page.wait_for_timeout(5000) # å¤šç­‰ä¸€ä¸‹è®“ API è·‘å®Œ
            
            # æ¨™è¨»åˆ†é¡
            for p_item in all_products:
                if p_item["category"] == "æœªåˆ†é¡":
                    p_item["category"] = cat_name

        # å¯«å…¥ Supabase
        if all_products:
            print(f"ğŸ’¾ ç¸½å…±å–å¾— {len(all_products)} ç­†è³‡æ–™ï¼Œæº–å‚™å­˜å…¥ Supabase...")
            # å»é‡
            unique_data = {v['title']: v for v in all_products}.values()
            supabase.table("poya_items").upsert(list(unique_data), on_conflict="title").execute()
            print("âœ… ä»»å‹™å®Œæˆï¼")
        else:
            print("âŒ ä¾ç„¶æ””æˆªä¸åˆ°æ•¸æ“šã€‚é€™ä»£è¡¨å¯¶é›…å°é–äº† GitHub çš„é€£ç·šã€‚")

        browser.close()

if __name__ == "__main__":
    scrape_poya()
